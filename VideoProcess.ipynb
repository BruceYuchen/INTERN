{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Combining resized Frames in Video (if need)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f21d5658e54268ba"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "# Setting pathway\n",
    "image_folder = '/Users/yz/Files/CODES/INTERN/Bottle-1/test/images'  # Pathway of images\n",
    "video_path = '/Users/yz/Files/CODES/INTERN/Bottle-1/test/output_video.mp4'  # Pathway of output\n",
    "\n",
    "# Setting attributes\n",
    "images = [img for img in os.listdir(image_folder) if img.endswith(\".jpg\")]\n",
    "frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "height, width, layers = frame.shape\n",
    "fps = 30  # fps of output\n",
    "\n",
    "# Create VideoWriter\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  \n",
    "video = cv2.VideoWriter(video_path, fourcc, fps, (width, height))\n",
    "\n",
    "# Adding frames in Video\n",
    "for image in sorted(images):\n",
    "    video.write(cv2.imread(os.path.join(image_folder, image)))\n",
    "\n",
    "# Release storage\n",
    "cv2.destroyAllWindows()\n",
    "video.release()\n",
    "\n",
    "print(\"Video created successfully!\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bea575dc254c1b5a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2.Require YOLOv8 Model via API"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c141e8e75438a9f3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!pip install roboflow"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ecabcb9cf6d245fa"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    "from roboflow import Roboflow\n",
    "\n",
    "# Assuming you've already installed Roboflow with pip install roboflow\n",
    "api_key = \"zt26bVuyi5xf9yizf4i2\"\n",
    "workspace = \"12-jqvcq\"\n",
    "project_name = \"bottle-oebjd\"\n",
    "version_number = 1\n",
    "\n",
    "\n",
    "# Initialize Roboflow model\n",
    "rf = Roboflow(api_key=api_key)\n",
    "project = rf.workspace(workspace).project(project_name)\n",
    "version = project.version(version_number)\n",
    "model = version.model\n",
    "\n",
    "\n",
    "# Open the video\n",
    "cap = cv2.VideoCapture('/Users/yz/Files/CODES/INTERN/Bottle-1/test/AA.mp4')\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('/Users/yz/Files/CODES/INTERN/Bottle-1/test/outAA.mp4', fourcc, fps, (width, height))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9e474b011de86f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3.1 Objecting and Tracking items start with 0 counts without Interface"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1dd9098364bd71f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    "from roboflow import Roboflow\n",
    "import numpy as np\n",
    "\n",
    "# Initialize your video capture, model, and other necessary parts above this code\n",
    "\n",
    "mid_line = height*9// 15\n",
    "line_color = (255, 0, 0)  # Red color in BGR\n",
    "line_thickness = 2\n",
    "\n",
    "# Dictionary to track objects\n",
    "trackers = {}\n",
    "\n",
    "\n",
    "item_appear_under_line = int(0)\n",
    "item_appear_over_line = int(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    cv2.line(frame, (0, mid_line), (width, mid_line), line_color, line_thickness)\n",
    "\n",
    "    # Apply model to each frame\n",
    "    predictions = model.predict(frame)\n",
    "    for prediction in predictions:\n",
    "        x, y, w, h = int(prediction['x']), int(prediction['y']), int(prediction['width']), int(prediction['height'])\n",
    "        center_y = y + h\n",
    "        label = prediction['class']\n",
    "        id_found = None\n",
    "\n",
    "        # Find the closest existing tracker (simple overlap or centroid distance)\n",
    "        for obj_id, (obj_label, obj_bbox, obj_last_y, obj_crossed) in trackers.items():\n",
    "            if label == obj_label and not obj_crossed and np.abs(obj_last_y - center_y) < 300:  # 200 pixels threshold\n",
    "                id_found = obj_id\n",
    "                break\n",
    "\n",
    "        if id_found is None:\n",
    "            # New object detected\n",
    "            new_id = max(trackers.keys(), default=-1) + 1\n",
    "            trackers[new_id] = (label, (x, y, w, h), center_y, False)\n",
    "        else:\n",
    "            # Update existing tracker\n",
    "            _, _, obj_last_y, obj_crossed = trackers[id_found]\n",
    "            if center_y < mid_line and obj_last_y >= mid_line and not obj_crossed:\n",
    "                item_count[label] += 1  # Update this logic based on your needs\n",
    "                trackers[id_found] = (label, (x, y, w, h), center_y, True)\n",
    "            elif center_y > mid_line and obj_last_y <= mid_line and not obj_crossed:\n",
    "                item_count[label] -= 1\n",
    "                trackers[id_found] = (label, (x, y, w, h), center_y, True)\n",
    "            else:\n",
    "                trackers[id_found] = (label, (x, y, w, h), center_y, obj_crossed)\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"{label} {prediction['confidence']:.2f}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    # Display item counts in the bottom-left corner of the frame\n",
    "    text_position = (10, height - 10)\n",
    "    for key, value in item_count.items():\n",
    "        display_text = f\"{key}: {value}\"\n",
    "        cv2.putText(frame, display_text, text_position, cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        text_position = (text_position[0], text_position[1] - 30)  # Adjust this value based on your font size\n",
    "\n",
    "    # Write the frame into the file\n",
    "    out.write(frame)\n",
    "\n",
    "    # Clean up trackers that are no longer in view\n",
    "    trackers = {obj_id: v for obj_id, v in trackers.items() if v[2] > 0 or v[2] < height}\n",
    "\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Item counts:\", item_count)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a3f7a4de980c858"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3.2 Objecting and Tracking items with self-identified Interface"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4dba100d63352b35"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    "from roboflow import Roboflow\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "\n",
    "# Predefined list of items (you can modify this list or read from a file)\n",
    "KNOWN_ITEMS = ['Bottle', 'R_Lunch']\n",
    "\n",
    "class ItemCountInitializer(tk.Toplevel):\n",
    "    def __init__(self, parent):\n",
    "        super().__init__(parent)\n",
    "        self.title(\"Initialize Item Counts\")\n",
    "        self.geometry(\"300x400\")\n",
    "        self.item_counts = {}\n",
    "\n",
    "        self.create_widgets()\n",
    "\n",
    "    def create_widgets(self):\n",
    "        for item in KNOWN_ITEMS:\n",
    "            frame = ttk.Frame(self)\n",
    "            frame.pack(pady=5, padx=10, fill='x')\n",
    "\n",
    "            label = ttk.Label(frame, text=item)\n",
    "            label.pack(side='left')\n",
    "\n",
    "            count_var = tk.IntVar(value=0)\n",
    "            spinbox = ttk.Spinbox(frame, from_=0, to=1000, textvariable=count_var, width=5)\n",
    "            spinbox.pack(side='right')\n",
    "\n",
    "            self.item_counts[item] = count_var\n",
    "\n",
    "        submit_button = ttk.Button(self, text=\"Submit\", command=self.on_submit)\n",
    "        submit_button.pack(pady=10)\n",
    "\n",
    "    def on_submit(self):\n",
    "        for item, var in self.item_counts.items():\n",
    "            self.item_counts[item] = var.get()\n",
    "        self.destroy()\n",
    "\n",
    "def get_initial_counts():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    dialog = ItemCountInitializer(root)\n",
    "    root.wait_window(dialog)\n",
    "    return dialog.item_counts\n",
    "\n",
    "# Function to display final counts (unchanged)\n",
    "def show_final_counts(item_count):\n",
    "    result_window = tk.Toplevel()\n",
    "    result_window.title(\"Final Item Counts\")\n",
    "    result_window.geometry(\"300x400\")\n",
    "\n",
    "    tree = ttk.Treeview(result_window, columns=('Item', 'Count'), show='headings')\n",
    "    tree.heading('Item', text='Item')\n",
    "    tree.heading('Count', text='Count')\n",
    "    tree.pack(fill='both', expand=True)\n",
    "\n",
    "    for item, count in item_count.items():\n",
    "        tree.insert('', 'end', values=(item, count))\n",
    "\n",
    "    close_button = ttk.Button(result_window, text=\"Close\", command=result_window.destroy)\n",
    "    close_button.pack(pady=10)\n",
    "\n",
    "    result_window.mainloop()\n",
    "\n",
    "# Get initial item counts from user\n",
    "item_count = get_initial_counts()\n",
    "\n",
    "# Initialize your video capture, model, and other necessary parts here\n",
    "# ...\n",
    "\n",
    "mid_line = height*9// 15\n",
    "line_color = (255, 0, 0)  # Red color in BGR\n",
    "line_thickness = 2\n",
    "\n",
    "# Dictionary to track objects\n",
    "trackers = {}\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    cv2.line(frame, (0, mid_line), (width, mid_line), line_color, line_thickness)\n",
    "\n",
    "    # Apply model to each frame\n",
    "    predictions = model.predict(frame)\n",
    "    for prediction in predictions:\n",
    "        x, y, w, h = int(prediction['x']), int(prediction['y']), int(prediction['width']), int(prediction['height'])\n",
    "        center_y = y + h\n",
    "        label = prediction['class']\n",
    "        \n",
    "        # Initialize count for new items\n",
    "        if label not in item_count:\n",
    "            item_count[label] = 0\n",
    "\n",
    "        id_found = None\n",
    "\n",
    "        # Find the closest existing tracker (simple overlap or centroid distance)\n",
    "        for obj_id, (obj_label, obj_bbox, obj_last_y, obj_crossed) in trackers.items():\n",
    "            if label == obj_label and not obj_crossed and np.abs(obj_last_y - center_y) < 300:  # 300 pixels threshold\n",
    "                id_found = obj_id\n",
    "                break\n",
    "\n",
    "        if id_found is None:\n",
    "            # New object detected\n",
    "            new_id = max(trackers.keys(), default=-1) + 1\n",
    "            trackers[new_id] = (label, (x, y, w, h), center_y, False)\n",
    "        else:\n",
    "            # Update existing tracker\n",
    "            _, _, obj_last_y, obj_crossed = trackers[id_found]\n",
    "            if center_y < mid_line and obj_last_y >= mid_line and not obj_crossed:\n",
    "                item_count[label] -= 1\n",
    "                trackers[id_found] = (label, (x, y, w, h), center_y, True)\n",
    "            elif center_y > mid_line and obj_last_y <= mid_line and not obj_crossed:\n",
    "                item_count[label] += 1\n",
    "                trackers[id_found] = (label, (x, y, w, h), center_y, True)\n",
    "            else:\n",
    "                trackers[id_found] = (label, (x, y, w, h), center_y, obj_crossed)\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"{label} {prediction['confidence']:.2f}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    # Display item counts in the bottom-left corner of the frame\n",
    "    text_position = (10, height - 10)\n",
    "    for key, value in item_count.items():\n",
    "        display_text = f\"{key}: {value}\"\n",
    "        cv2.putText(frame, display_text, text_position, cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        text_position = (text_position[0], text_position[1] - 30)  # Adjust this value based on your font size\n",
    "\n",
    "    # Write the frame into the file\n",
    "    out.write(frame)\n",
    "\n",
    "    # Clean up trackers that are no longer in view\n",
    "    trackers = {obj_id: v for obj_id, v in trackers.items() if v[2] > 0 or v[2] < height}\n",
    "\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Show final counts in a GUI window\n",
    "show_final_counts(item_count)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e695f873fd50253",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3.3 If the input video is not in 640*640 (resizing might take longer time)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c856962786bf6391"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from roboflow import Roboflow\n",
    "\n",
    "# Predefined list of items (you can modify this list or read from a file)\n",
    "KNOWN_ITEMS = ['Bottle', 'R_Lunch']\n",
    "\n",
    "# Target size for video frames\n",
    "TARGET_SIZE = (640, 640)\n",
    "\n",
    "class ItemCountInitializer(tk.Toplevel):\n",
    "    def __init__(self, parent):\n",
    "        super().__init__(parent)\n",
    "        self.title(\"Initialize Item Counts\")\n",
    "        self.geometry(\"300x400\")\n",
    "        self.item_counts = {}\n",
    "\n",
    "        self.create_widgets()\n",
    "\n",
    "    def create_widgets(self):\n",
    "        for item in KNOWN_ITEMS:\n",
    "            frame = ttk.Frame(self)\n",
    "            frame.pack(pady=5, padx=10, fill='x')\n",
    "\n",
    "            label = ttk.Label(frame, text=item)\n",
    "            label.pack(side='left')\n",
    "\n",
    "            count_var = tk.IntVar(value=0)\n",
    "            spinbox = ttk.Spinbox(frame, from_=0, to=1000, textvariable=count_var, width=5)\n",
    "            spinbox.pack(side='right')\n",
    "\n",
    "            self.item_counts[item] = count_var\n",
    "\n",
    "        submit_button = ttk.Button(self, text=\"Submit\", command=self.on_submit)\n",
    "        submit_button.pack(pady=10)\n",
    "\n",
    "    def on_submit(self):\n",
    "        for item, var in self.item_counts.items():\n",
    "            self.item_counts[item] = var.get()\n",
    "        self.destroy()\n",
    "\n",
    "def get_initial_counts():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    dialog = ItemCountInitializer(root)\n",
    "    root.wait_window(dialog)\n",
    "    return dialog.item_counts\n",
    "\n",
    "def show_final_counts(item_count):\n",
    "    result_window = tk.Toplevel()\n",
    "    result_window.title(\"Final Item Counts\")\n",
    "    result_window.geometry(\"300x400\")\n",
    "\n",
    "    tree = ttk.Treeview(result_window, columns=('Item', 'Count'), show='headings')\n",
    "    tree.heading('Item', text='Item')\n",
    "    tree.heading('Count', text='Count')\n",
    "    tree.pack(fill='both', expand=True)\n",
    "\n",
    "    for item, count in item_count.items():\n",
    "        tree.insert('', 'end', values=(item, count))\n",
    "\n",
    "    close_button = ttk.Button(result_window, text=\"Close\", command=result_window.destroy)\n",
    "    close_button.pack(pady=10)\n",
    "\n",
    "    result_window.mainloop()\n",
    "\n",
    "# Get initial item counts from user\n",
    "item_count = get_initial_counts()\n",
    "\n",
    "# Initialize your video capture\n",
    "cap = cv2.VideoCapture('path_to_your_video.mp4')  # Replace with your video path\n",
    "\n",
    "# Get original video properties\n",
    "orig_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "orig_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Calculate scaling factors\n",
    "scale_x = TARGET_SIZE[0] / orig_width\n",
    "scale_y = TARGET_SIZE[1] / orig_height\n",
    "\n",
    "# Initialize video writer with resized dimensions\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('output_video.mp4', fourcc, fps, TARGET_SIZE)\n",
    "\n",
    "# Initialize your model here\n",
    "# model = ...\n",
    "\n",
    "# Calculate the position of the middle line for the resized frame\n",
    "mid_line = TARGET_SIZE[1] * 9 // 15\n",
    "line_color = (255, 0, 0)  # Red color in BGR\n",
    "line_thickness = 2\n",
    "\n",
    "# Dictionary to track objects\n",
    "trackers = {}\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize frame to target size\n",
    "    frame = cv2.resize(frame, TARGET_SIZE)\n",
    "\n",
    "    cv2.line(frame, (0, mid_line), (TARGET_SIZE[0], mid_line), line_color, line_thickness)\n",
    "\n",
    "    # Apply model to each frame\n",
    "    predictions = model.predict(frame)\n",
    "    for prediction in predictions:\n",
    "        x, y, w, h = int(prediction['x']), int(prediction['y']), int(prediction['width']), int(prediction['height'])\n",
    "        center_y = y + h // 2\n",
    "        label = prediction['class']\n",
    "        \n",
    "        # Initialize count for new items\n",
    "        if label not in item_count:\n",
    "            item_count[label] = 0\n",
    "\n",
    "        id_found = None\n",
    "\n",
    "        # Find the closest existing tracker (simple overlap or centroid distance)\n",
    "        for obj_id, (obj_label, obj_bbox, obj_last_y, obj_crossed) in trackers.items():\n",
    "            if label == obj_label and not obj_crossed and np.abs(obj_last_y - center_y) < 300:  # 300 pixels threshold\n",
    "                id_found = obj_id\n",
    "                break\n",
    "\n",
    "        if id_found is None:\n",
    "            # New object detected\n",
    "            new_id = max(trackers.keys(), default=-1) + 1\n",
    "            trackers[new_id] = (label, (x, y, w, h), center_y, False)\n",
    "        else:\n",
    "            # Update existing tracker\n",
    "            _, _, obj_last_y, obj_crossed = trackers[id_found]\n",
    "            if center_y < mid_line and obj_last_y >= mid_line and not obj_crossed:\n",
    "                item_count[label] += 1\n",
    "                trackers[id_found] = (label, (x, y, w, h), center_y, True)\n",
    "            elif center_y > mid_line and obj_last_y <= mid_line and not obj_crossed:\n",
    "                item_count[label] -= 1\n",
    "                trackers[id_found] = (label, (x, y, w, h), center_y, True)\n",
    "            else:\n",
    "                trackers[id_found] = (label, (x, y, w, h), center_y, obj_crossed)\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"{label} {prediction['confidence']:.2f}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    # Display item counts in the bottom-left corner of the frame\n",
    "    text_position = (10, TARGET_SIZE[1] - 10)\n",
    "    for key, value in item_count.items():\n",
    "        display_text = f\"{key}: {value}\"\n",
    "        cv2.putText(frame, display_text, text_position, cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        text_position = (text_position[0], text_position[1] - 30)  # Adjust this value based on your font size\n",
    "\n",
    "    # Write the frame into the file\n",
    "    out.write(frame)\n",
    "\n",
    "    # Clean up trackers that are no longer in view\n",
    "    trackers = {obj_id: v for obj_id, v in trackers.items() if v[2] > 0 or v[2] < TARGET_SIZE[1]}\n",
    "\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Show final counts in a GUI window\n",
    "show_final_counts(item_count)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2936db7de8eab38d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
